{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e36d741",
   "metadata": {},
   "source": [
    "## Policy Checker AgenticAI Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c18801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee3985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from typing import TypedDict\n",
    "from langchain_openai import ChatOpenAI \n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "\n",
    "\n",
    "SQL_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a SQL Query Generator. Please note You are SQL Query Generator for Microsoft SQL Server. \n",
    "\n",
    "Given an question, create a syntactically correct query to run to help find the answer.\n",
    "Unless the User specifies in his questions a specific number of examples they want to obtain, always limit your query to at most top 6 results. \n",
    "You can order the results by a relevant columns to return the most interesting examples in the database.\n",
    "\n",
    "Never query for all the columns from a specific table, only ask for a few relevant columns given the question.\n",
    "\n",
    "Pay attention to use only the column names that you can see in the schema description.\n",
    "Be careful to not query for columns that do not exist.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT = \"Question: {input_text}\"\n",
    "\n",
    "\n",
    "# First define a structured output\n",
    "class EvaluatorOutput(BaseModel):\n",
    "    sql_query: str = Field(description=\"structured SQL query response from the User's question\")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0)\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: str\n",
    "    result: str\n",
    "    answer: str\n",
    "\n",
    "\n",
    "class SQL_chain():\n",
    "\n",
    "    @staticmethod\n",
    "    def conversion_in_sql_query(state: State) -> State:\n",
    "        \"\"\"llm will generate natural language to structured sql query\"\"\"\n",
    "        \n",
    "        query_prompt_template = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", SQL_SYSTEM_MESSAGE), \n",
    "            (\"user\", USER_PROMPT)\n",
    "            ])\n",
    "\n",
    "        structured_llm = llm.with_structured_output(EvaluatorOutput)\n",
    "        print(structured_llm)\n",
    "\n",
    "        \n",
    "        ## format the prompt\n",
    "        messages = query_prompt_template.format_messages(input_text=state[\"question\"])\n",
    "        \n",
    "        ## run llm to generate sql query\n",
    "        result: EvaluatorOutput = structured_llm.invoke(messages)\n",
    "        \n",
    "        ## update state with query\n",
    "        state[\"query\"] = result.sql_query\n",
    "\n",
    "        return state\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38c74ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000266DA7A56D0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000266DC7E2510>, root_client=<openai.OpenAI object at 0x00000266DC2A3590>, root_async_client=<openai.AsyncOpenAI object at 0x00000266DA7FF5D0>, model_name='gpt-4.1', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'response_format': <class '__main__.EvaluatorOutput'>, 'ls_structured_output_format': {'kwargs': {'method': 'json_schema', 'strict': None}, 'schema': {'type': 'function', 'function': {'name': 'EvaluatorOutput', 'description': '', 'parameters': {'properties': {'sql_query': {'description': \"structured SQL query response from the User's question\", 'type': 'string'}}, 'required': ['sql_query'], 'type': 'object'}}}}}, config={}, config_factories=[]) middle=[] last=RunnableBinding(bound=RunnableLambda(...), kwargs={}, config={}, config_factories=[], custom_output_type=<class '__main__.EvaluatorOutput'>)\n",
      "Generated SQL Query:\n",
      " SELECT TOP 6 employee_id, first_name, last_name, salary\n",
      "FROM employees\n",
      "WHERE salary > 40000\n",
      "ORDER BY salary DESC;\n"
     ]
    }
   ],
   "source": [
    "state = {\n",
    "    \"question\": \"find employees whose salary is more than 40000.\",\n",
    "    \"query\": \"\",\n",
    "    \"result\": \"\",\n",
    "    \"answer\": \"\"\n",
    "}\n",
    "\n",
    "new_state = SQL_chain.conversion_in_sql_query(state)\n",
    "print(\"Generated SQL Query:\\n\", new_state[\"query\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0189ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "\n",
    "def run_sql_query(query: str):\n",
    "    \"\"\" execute the sql query\"\"\"\n",
    "\n",
    "    # SQL server connection details\n",
    "    server = r\"DESKTOP-6SIQQDV\\INSTANCE2022\"\n",
    "    database = \"ABC_Company\"\n",
    "    username = \"sa\"\n",
    "    password = \"Sagar@12\"\n",
    "\n",
    "\n",
    "    # Connection string for SQL Authentication\n",
    "    conn_str = (\n",
    "        f\"DRIVER={{ODBC Driver 17 for SQL Server}};\"\n",
    "        f\"SERVER={server};\"\n",
    "        f\"DATABASE={database};\"\n",
    "        f\"UID={username};\"\n",
    "        f\"PWD={password};\"\n",
    "        f\"Encrypt=no;\"\n",
    "    )\n",
    "\n",
    "    # connect to database\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "\n",
    "    cursor.execute(query)\n",
    "    rows = cursor.fetchall()            # ferch rows\n",
    "\n",
    "\n",
    "    ## convert rows to readable list\n",
    "    columns = [column[0] for column in cursor.description]\n",
    "    result = [dict(zip(columns, row)) for row in rows]\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27612c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000266DA7A56D0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000266DC7E2510>, root_client=<openai.OpenAI object at 0x00000266DC2A3590>, root_async_client=<openai.AsyncOpenAI object at 0x00000266DA7FF5D0>, model_name='gpt-4.1', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'response_format': <class '__main__.EvaluatorOutput'>, 'ls_structured_output_format': {'kwargs': {'method': 'json_schema', 'strict': None}, 'schema': {'type': 'function', 'function': {'name': 'EvaluatorOutput', 'description': '', 'parameters': {'properties': {'sql_query': {'description': \"structured SQL query response from the User's question\", 'type': 'string'}}, 'required': ['sql_query'], 'type': 'object'}}}}}, config={}, config_factories=[]) middle=[] last=RunnableBinding(bound=RunnableLambda(...), kwargs={}, config={}, config_factories=[], custom_output_type=<class '__main__.EvaluatorOutput'>)\n",
      "SELECT TOP 6 EmployeeID, FirstName, LastName, Salary\n",
      "FROM Employees\n",
      "WHERE Salary > 40000\n",
      "ORDER BY Salary DESC;\n",
      "\n",
      " Query result\n",
      "{'EmployeeID': 36, 'FirstName': 'Sharad', 'LastName': 'Shinde', 'Salary': Decimal('135000.00')}\n",
      "{'EmployeeID': 6, 'FirstName': 'Amit', 'LastName': 'Khanna', 'Salary': Decimal('120000.00')}\n",
      "{'EmployeeID': 14, 'FirstName': 'Alisha', 'LastName': 'Merchant', 'Salary': Decimal('115000.00')}\n",
      "{'EmployeeID': 31, 'FirstName': 'Sameer', 'LastName': 'Shaikh', 'Salary': Decimal('110000.00')}\n",
      "{'EmployeeID': 8, 'FirstName': 'Deepak', 'LastName': 'Rane', 'Salary': Decimal('98000.00')}\n",
      "{'EmployeeID': 26, 'FirstName': 'Rahul', 'LastName': 'Jain', 'Salary': Decimal('98000.00')}\n"
     ]
    }
   ],
   "source": [
    "state = {\n",
    "    \"question\": \"find employees whose salary is more than 40000.\",\n",
    "    \"query\": \"\",\n",
    "    \"result\": \"\",\n",
    "    \"answer\": \"\"\n",
    "}\n",
    "\n",
    "new_state = SQL_chain.conversion_in_sql_query(state)\n",
    "print(new_state[\"query\"])\n",
    "\n",
    "\n",
    "records = run_sql_query(new_state[\"query\"])\n",
    "new_state[\"result\"] = records\n",
    "\n",
    "print(\"\\n Query result\")\n",
    "for row in records:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "787f556b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You asked to find employees whose salary is more than 40,000.\n",
      "\n",
      "The results show a list of employees who earn above that amount, along with their names and salaries.\n",
      "\n",
      "Key employees with their salaries:\n",
      "- Sharad Shinde: 135,000\n",
      "- Amit Khanna: 120,000\n",
      "- Alisha Merchant: 115,000\n",
      "- Sameer Shaikh: 110,000\n",
      "- Deepak Rane: 98,000\n",
      "- Rahul Jain: 98,000\n",
      "\n",
      "All these employees have salaries well above 40,000. Let me know if you need more details or want to filter this list further!\n"
     ]
    }
   ],
   "source": [
    "# from langchain.chains import LLMChain              ## deprecated this line code soon, hence adding \"RunnableSequence\"\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "#from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "# ### Explain back structured SQL query result in simple language to User\n",
    "# explain_prompt = PromptTemplate(\n",
    "#     input_variables = [\"question\", \"result\"],\n",
    "#     template = \"\"\"\n",
    "#     You are a helpful data analyst.\n",
    "#     The user asked: {question}, and here is the SQL query output {result}.\n",
    "#     Your job to read the question and analyse the SQL query. Explain back result to User in simple, friendly language.\n",
    "#     Do not show SQL, only explain the meaning, and if any observations about the data.\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# # explain_chain = LLMChain(llm=llm, prompt=explain_prompt)      ## deprecated this line code soon\n",
    "# explain_chain = explain_prompt | llm\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "### Explain back structured SQL query result in simple language to User\n",
    "simple_explain_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "    \"\"\"\n",
    "    You are a helpful assistant who explains SQL query results in simple, natural language.\n",
    "\n",
    "\n",
    "    Output Style:\n",
    "    - Briefly restate the user's request\n",
    "    - Summarize what the results show\n",
    "    - Bullet list of key rows (Name and Salary or similar fields)\n",
    "    - One concluding sentence\n",
    "    - End with a short, helpful conclusion\n",
    "\n",
    "\n",
    "\n",
    "    Do NOT use tables.\n",
    "    Just speak like you're summarizing to a colleague.\n",
    "    \"\"\"\n",
    "    ),\n",
    "    (\"user\",\n",
    "    \"Question: {question}\\n\\nQuery Result: {result}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def explain_result(state):\n",
    "    explaination = (simple_explain_prompt | llm).invoke({\n",
    "        \"question\": state[\"question\"],\n",
    "        \"result\": state[\"result\"]\n",
    "    })\n",
    "    state[\"answer\"] = explaination.content\n",
    "    return state\n",
    "\n",
    "new_state = explain_result(new_state)\n",
    "print(new_state[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0992d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
